# Train run will save at: main_path/%y%m%d_%H%M%S_%description"
paths_yamlfile: diffusion/coco_configs/data_paths.yaml # use <> to set up paths according to the server
main_path: /data1/erez/Documents/sidd/diffusion_coco_storage
# load: '' # use -f argument
# sub_dir_tstsave: 0_tests # NU
load_file: emabkup_0.9999_1200000.pt # or use --lf ; file name to load from folder given by (-f/ argument
#load_file: model010000.pt # or use --lf ; file name to load from folder given by (-f/ argument
# resume_checkpoint: /data1/erez/Documents/diffusion_flatcam/230308_1923_flatnetcond_ssim02_resume70k/model180000.pt
#resume_ema_opt: False
format_strs: log,csv,wandb
wandb_project: diffusion_coco_sample
job_type: concat_s_sample
wandb_tags: ['concat_sample', 's21']


#MODEL_FLAGS
image_size: 128
input_channels: 8 # 3 for diffusion + 3 / 4 for concat rgb/raw image
out_channels: 4
num_channels: 128 # 128
num_res_blocks: 3
# learn_sigma: False # True
model_var_type_name: fixed_large  # learned_sigma / fixed_small / fixed_large (default)
model_mean_type_name: xstart # xprev / epsilon / xstart
class_cond: False # True for clip embd adaGN
loss_type_name: l1 # todo think
attention_resolutions: '' # 16,problem # D:16,8, REC: 32,16,8 # todo check working
num_heads: 1 # D:4
xf_width: 768 # 512 # size of clip embedding
# dropout 0.1 ?? #D:0.0

# num_head_channels 64 ?
# resblock_updown True ? #D:False
use_fp16: False # D:False

#DIFFUSION_FLAGS
diffusion_type: base # dvir_unet # noise_diffusion, soft # todo fix
model_type: concat_condition_nulllabel
diffusion_steps: 1000
noise_schedule: cosine #linear
ema_rate: 0.9999,0.9997, 0.9992 # todo think check
#Reweighted VLB?

#TRAIN_FLAGS
lr: 0.0001
batch_size: 8 # todo fix 6
batches_accumulate_grads: 1
save_interval: 2000 # todo fix # save every 5 times by step number. otherwise save as 'latest' and override.
log_interval: 500
num_workers: 8
train_noise_percent: 0 #3.13 # todo
test_noise_percent: 0 #3.13 #
islora: True
#lora_checkpoint: null # /data1/erez/Documents/sidd/diffusion_coco/230730_0025_lora_cont_cond_1M/model1000000.pt
lora_checkpoint: /data1/erez/Documents/sidd/diffusion_coco/230810_1313_lora_cat_s21/ema_0.9999_1300000.pt
# DATASET:
#dataset_type: s7
dataset_type: s21
fpath_gt: iso50_t1-50
fpath_noisy: iso3200_t1-12000

trim_len: 0
clip_dataset: False # for contidition on clip data
save_all_samples: True # set to save samples in folder on inference
deterministic_seed_noise: 0 # set seed to the dataset loading


# paths:
# main_data_path: /data2/erez/datasets/coco_captions/raw_imgs/NU? # NU: disk bottleneck use crops
main_data_path_train: /data2/erez/datasets/denoising/s21_256/
main_data_path_val: /data2/erez/datasets/denoising/s21_256/
# val_percent: 0.1

#  CUDA_VISIBLE_DEVICES=1 python diffusion/image_sample.py --config_file diffusion/coco_configs/s_condition_sample_config.yaml -f 1923 -d firsttes



# PREVIOUS OLDER CODES:
# DATA
# data_dir: /data2/erez/datasets/faces/raw_data/thumbnails128x128/
# clip_file_path: /data2/erez/datasets/faces/raw_data/thumbnails128x128_ViT-B32_dict.pt

# data_dir_test: /data2/erez/datasets/faces/raw_data/celeba_hq_256/
# clip_file_path_test: /data2/erez/datasets/faces/raw_data/clip_embd_celeba_hq_256_ViT-B32_dict.pt
# num_workers: 4

# DIFFUSION_TRAINING_TEST CUDA_VISIBLE_DEVICES=2 python scripts/image_train.py -d description
# CUDA_VISIBLE_DEVICES=2 python scripts/super_res_train.py -d description

# CUDA_VISIBLE_DEVICES=0 python scripts/image_train.py --config_file configs/cold_train_config.yaml -d cold_sample

